{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7445d3f-0e57-4a40-a4d0-24bdea989563",
   "metadata": {},
   "source": [
    "# 07. PyTorch Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63a8de-bdfc-4ff7-a6bd-da482da1969a",
   "metadata": {},
   "source": [
    "We've trained a few models now on the journey to making FoodVision.\n",
    "\n",
    "And so far we've kept track of them via `Python Dictionaries` or just comparing them by the metric print outs during training.\n",
    "\n",
    "**but, what if we want to run a dozen (or more) different models at once?**\n",
    "\n",
    "There's a better way to keep track of the models.\n",
    "\n",
    "It's called `Experiment Tracking`.\n",
    "\n",
    "and experiment tracking is very important and integral to machine learning.\n",
    "\n",
    "Since it is an important topic, you can consider this notebook your first milestone project.\n",
    "\n",
    "So welcome to `Milestone Project 1: FoodVision Mini Experiment Tracking`\n",
    "\n",
    "we are going to see `how we can track our machine learning experiments`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dced230-6d79-4944-8ad3-dd16996fead2",
   "metadata": {},
   "source": [
    "## What is experiment tracking?\n",
    "If the number of experiments we run starts to increase, this naive way of tracking the results with print out and dictionaries could get out of hand.\n",
    "\n",
    "So, if we're following the machine learning practitioner's motto of experiment, experiment, experiment, we'll want to track them all.\n",
    "\n",
    "![](07_experiment_tracking.png)\n",
    "\n",
    "Now, when we have this many models and tracking their results, we'll start to notice how quickly it can get out of hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6a586-1e97-4533-b0d1-fc96e604537f",
   "metadata": {},
   "source": [
    "## Different ways to track machine learning experiments.\n",
    "\n",
    "There are many different ways to track machine learning experiments as there is experiments to run.\n",
    "\n",
    "Few of them are.\n",
    "| Method | Setup | Pros | Cons | Cost |\n",
    "| ------ | ----- | ---- | ---- | ---- |\n",
    "| PyThon dictionaries, csv files, printouts | None | Easy to setup, runs in pure python | Hard to keep track of large numbers of experiments | Free |\n",
    "| **Tensorboard** | minimal, install `tensorboard` | Extensions built into PyTorch, widely recognized and used, easily scales. | User-experience not as nice as other options. | Free |\n",
    "| **Weights and Biases Experiment Tracking** | Minimal, install `wandb`, make an account | Incredible user experience, make experiments public, tracks almost anything. | Requires external resource outside of PyTorch. | Free for personal use |\n",
    "| MLFlow | Minimal, install `mlflow` and starting tracking | Fully open-source MLOps lifecycle management, many integrations. | Little bit harder to setup a remote tracking server than other services. | Free |\n",
    "\n",
    "![](expriment_tracking_ways.png)\n",
    "\n",
    "**Note:** There are more than these, which we can search online later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f78d6b-5fc0-4b72-9ee5-aff82dc30472",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "\n",
    "we're going to run several different modeling experiments with various levels of data, model size, and training time to try and improve on FoodVision.\n",
    "\n",
    "We'll look at `TensorBoard` to track our experiments. Cause it is tighly integrated with PyTorch and it is widely used.\n",
    "\n",
    "However, the principles we're going to cover are similar across all of the other tools for experiment tracking.\n",
    "\n",
    "Here are the topics we're going to cover:\n",
    "| Topic |\n",
    "| :-----: |\n",
    "| 0. Setting up |\n",
    "| 1. Get Data |\n",
    "| 2. Create **Datasets and DataLoaders** |\n",
    "| 3. Get and customize a **pretrained model** |\n",
    "| 4. **Train a model** and track the results |\n",
    "| 5. View our model's results in **`TensorBoard`** |\n",
    "| 6. Create a **helper function to track experiments** |\n",
    "| 7. **Setting** up a series of **modeling experiments** |\n",
    "| 8. **View modeling experiments** in TensorBoard |\n",
    "| 9. **load in the best model** and **make predictions** with it |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc8005-349e-48f8-a9b0-d416a1ae4da5",
   "metadata": {},
   "source": [
    "## 0. Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b6806-ac3a-4b81-bb49-dd9a99769367",
   "metadata": {},
   "source": [
    "To save us writing some code, we're going to be leveraging some of the Python scripts (such as `data_setup.py` and `engine.py`) we created in section `05. PyTorch Going Modular`\n",
    "\n",
    "Specifically, we're going to download the `going_modular` directory fromt he `pytorch-deep-learning` repository (if we don't already have it).\n",
    "\n",
    "we'll also get the `torchinfo` package if it's not available.\n",
    "\n",
    "`torchinfo` will help us letter to visualize the summaries of our model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a65030-0ab9-4a4d-a093-e0fb7e1b2016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.2\n",
      "torchvision version: 0.17.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'torchvision version: {torchvision.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d339ee3-ab43-4447-9322-69920fe23492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "try:\n",
    "    from going_modular.going_modular import data_setup, engine\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find going modular scripts, downloading them from the GitHub\")\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular ./\n",
    "    !rm -=rf pytorch-deep-learning\n",
    "    from going_modular import data_setup, engine\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5163a0-a223-436b-b207-9a7ebebcd1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b852f7-5ce2-40a0-b7d7-1e5079cd44ac",
   "metadata": {},
   "source": [
    "### create a helper function to set seeds\n",
    "\n",
    "since we've been setting random seeds a whole bunch throughout previous sections, how about we functionize it?\n",
    "\n",
    "let's create a function to 'set the seeds' called `set_seeds()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a849c74-bac3-4ce7-843c-d865a1101e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "\n",
    "def set_seeds(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seed: (int, optional): Random seed to set. Defaults to 42\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5926e-7c38-465b-b475-0e985b7f77f2",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "\n",
    "As always, before we can run machine learning experiments, we'll need a dataset.\n",
    "\n",
    "we're goig to continue trying to imporove upon the results we've been getting on FoodVision.\n",
    "\n",
    "In the previous section, 06. PyTorch Transfer Learning, we saw how powerful using a pretrained model and transfer learning could be when classifying images of pizza, steak, and sushi.\n",
    "\n",
    "**So, how about we run some experiments and try to further improve our results?**\n",
    "\n",
    "To do so, we'll use similar code to the previous section to download the pizza_steak_sushi.zip. **Except this time, its functionized.**\n",
    "\n",
    "This will allow us to use it again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ff3403-dfd6-4e6b-98c7-3e5e8e5724d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data/pizza_steak_sushi directory already exists. Skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def download_data(source: str,\n",
    "                  destination: str,\n",
    "                  remove_source: bool = True):\n",
    "    data_path = Path('data')\n",
    "    image_path = data_path / destination\n",
    "\n",
    "    # create the path if not existed\n",
    "    if image_path.is_dir():\n",
    "        print(f'[INFO] {image_path} directory already exists. Skipping download.')\n",
    "    else:\n",
    "        print(f\"[INFO] {image_path} doesn't exists. Creating one.\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path / target_file, 'wb') as f:\n",
    "            request = requests.get(source)\n",
    "            print('[INFO] Downloading...')\n",
    "            f.write(request.content)\n",
    "            print('Downloaded')\n",
    "        with ZipFile(data_path / target_file, 'r') as zip_file:\n",
    "            print(f'[INFO] Unzipping {target_file} data...')\n",
    "            zip_file.extractall(image_path)\n",
    "            print(f'[INFO] Extracted.')\n",
    "\n",
    "        # remove .zip file\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "    return image_path\n",
    "    \n",
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                           destination=\"pizza_steak_sushi\")\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddf00b-322e-475f-af64-228a391a0882",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders\n",
    "\n",
    "Now we've got some data, let's turn it into PyTorch DataLoaders.\n",
    "\n",
    "We can do so using the `create_dataloaders()` function from 05. PyTorch Going Modular.\n",
    "\n",
    "**Since we'll be using transfer learning and specifically pretrained models from `torchvision.models`, we'll create a transform to prepare our images correctly.**\n",
    "\n",
    "To Transform our images into tensors, we can use:\n",
    "1 Manually created transforms using `torchvision.transforms`\n",
    "2. Automatically create transforms using\n",
    "`torchvision.models.MODEL_NAME. MODEL_WEIGHTS.DEFAULT.transforms()`\n",
    "    - where `MODEL_NAME` is a specific torchvision.models architecture, `MODEL_WEIGHTS` is a specific set of pretrained weights and `DEFAULT` means the \"best available weights\".\n",
    "\n",
    "We will see the manual transformation here. And for that, we need to be sure that the images are normalized in `ImageNet` format (because `torchvision.models` are all pretrained in ImageNet)\n",
    "\n",
    "We can do this with:\n",
    "```\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ca969-837a-411a-9b07-3bebd85c21b8",
   "metadata": {},
   "source": [
    "### 2.1. Create DataLoaders using Manually created transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1eaa78-afbc-48ff-b1b4-47c72516ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually create transforms: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x112d7a380>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1273c1cf0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "# setup ImageNet normalization levels\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "# create transform pipeline manually\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "print(f'Manually create transforms: {manual_transforms}')\n",
    "\n",
    "# # create data loaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=manual_transforms,\n",
    "    batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde60f8b-4ce6-4500-b3e6-82282f561557",
   "metadata": {},
   "source": [
    "### 2.2 Create DataLoaders using automatically created transforms \n",
    "Let's create the same transforms using automatic transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cab96e0-5957-43a9-b22c-f2ed6038e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1273c1f60>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1273c2a10>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "# load weights from the pretrained model\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "automatic_transforms = weights.transforms()\n",
    "print(f'Automatically created transforms: {automatic_transforms}')\n",
    "\n",
    "# create train and test dataloaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=automatic_transforms,\n",
    "    batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80301b-5c22-46a3-9f99-553bbb1cdae6",
   "metadata": {},
   "source": [
    "## 3. Gettina a pretrained model, freezing the base layers and chaning the classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1d7426-197c-47d7-ae33-8c50966ee187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load pretrained model\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights)\n",
    "\n",
    "# freeze the parameters\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# change the classifier head\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280, out_features=3, bias=True)\n",
    ").to(device)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47760d96-5428-4f8d-8e8b-c1043a752dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the model info\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model,\n",
    "        input_size=(32,3,224,224), # same size as input of the model we imported\n",
    "        verbose=False,\n",
    "        col_width=20,\n",
    "        col_names=['input_size','output_size', 'num_params', 'trainable'],\n",
    "        row_settings=['var_names']\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda1fdb-06e0-4c88-b821-ecfdd7d9bfaa",
   "metadata": {},
   "source": [
    "## 4. Train model and track the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fcbed0d-d02d-4934-95b7-7a76ea7c340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets setup loss function and an optimiser\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cd8df-b6ad-4201-b235-f957e51b7675",
   "metadata": {},
   "source": [
    "### 4.1 Adjust `train()` function to track results with `SummaryWriter()`\n",
    "\n",
    "Let's add the final piece to track our experiments.\n",
    "\n",
    "Previously, we've tracked our modelling experiments using multiple Python dictionaries (one for each model)\n",
    "\n",
    "But we can image that this could get out of hand if we were running anything more than a few experiments.\n",
    "\n",
    "**`Not to worry, we have better options`**\n",
    "\n",
    "We can use PyTorch's `torch.utils.tensorboard.SummaryWriter()` class to save various parts of our model's training progress to file.\n",
    "\n",
    "By default, the `SummaryWriter()` class saves various information about our model to a file set by the `log_dir` parameters.\n",
    "\n",
    "The default location for `log_dir` is under `runs/CURRENT_DATETIME_HOSTNAME`, where the `HOSTNAME` is the name of our computer\n",
    "\n",
    "**The outputs of the `SummaryWriter()` are saved in [TensorBoard](https://www.tensorflow.org/tensorboard) format**\n",
    "\n",
    "Tensorboard is a part of the TensorFlow deep learning library and is an excellent way to visualize different parts of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be382380-ad11-4d59-b2cf-2f8e4753d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SummaryWriter() instance\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4dd1a1-00c0-4c1f-b3e3-766b87fb73c5",
   "metadata": {},
   "source": [
    "Now to use the writer, we have to create a training loop or use it in existing `train()` function.\n",
    "\n",
    "lets use the `train()` function from `engine.py` and adjust it to use `writer`\n",
    "\n",
    "Specifically, we'll add the ability for our `train()` function to log our model's training and test loss and accuracy values.\n",
    "\n",
    "We can do this with `writer.add_scalars(main,_tag, tag_scalar_dict), where:\n",
    "- `main_tag` (string) - the name for the scalers being tracked(eg. `accuracy`\n",
    "- `tag_scalar_dict` (dict) - a dictionary of the values being tracked (eg. `{'train_loss': 0.3454}`\n",
    "\n",
    "One we've finished tracking values, we'll call `writer.close()` to tell the `writer` to stop looking for values to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d14758-0f10-43a2-8d21-1c25a7e87deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int = 5,\n",
    "          device = torch.device) -> Dict[str, List]:\n",
    "    # create an empty results dictionary\n",
    "    results = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                           dataloader=test_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           device=device)\n",
    "        # print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # update results dictionary\n",
    "        results['train_loss'].append(train_loss)\n",
    "        results['train_acc'].append(train_acc)\n",
    "        results['test_loss'].append(test_loss)\n",
    "        results['test_acc'].append(test_acc)\n",
    "\n",
    "        ## New: Experiment tracking ##\n",
    "        # add loss results to SummaryWriter()\n",
    "        writer.add_scalars(main_tag=\"Loss\",\n",
    "                          tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                           \"test_loss\": test_loss\n",
    "                                          },\n",
    "                           global_step=epoch\n",
    "                         )\n",
    "        # add accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag='Accuracy',\n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc\n",
    "                                           },\n",
    "                           global_step=epoch\n",
    "                          )\n",
    "        # Track the PyTorch model architecture\n",
    "        writer.add_graph(model=model,\n",
    "                        # pass the example input\n",
    "                         input_to_model=torch.randn(32, 3, 224, 224).to(device)\n",
    "                        )\n",
    "    # close the writer\n",
    "    writer.close()\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62249-5cb8-4252-8228-466185eb9619",
   "metadata": {},
   "source": [
    "Now lets try to train themodel with 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db7b9f1-9055-4b2e-ab5e-16325fe7331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d0ad039385477fb7bd60648b2931d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0871 | train_acc: 0.3984 | test_loss: 0.9147 | test_acc: 0.6108\n",
      "Epoch: 2 | train_loss: 0.8945 | train_acc: 0.6836 | test_loss: 0.8354 | test_acc: 0.6411\n",
      "Epoch: 3 | train_loss: 0.7468 | train_acc: 0.9062 | test_loss: 0.6767 | test_acc: 0.9167\n",
      "Epoch: 4 | train_loss: 0.6701 | train_acc: 0.7812 | test_loss: 0.6351 | test_acc: 0.9062\n",
      "Epoch: 5 | train_loss: 0.6285 | train_acc: 0.8203 | test_loss: 0.6249 | test_acc: 0.8759\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "set_seeds()\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de8db32-88e0-457a-b078-a00e4e3952f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.087058961391449,\n",
       "  0.8945116028189659,\n",
       "  0.7468452602624893,\n",
       "  0.6701110824942589,\n",
       "  0.6285387836396694],\n",
       " 'train_acc': [0.3984375, 0.68359375, 0.90625, 0.78125, 0.8203125],\n",
       " 'test_loss': [0.9146990776062012,\n",
       "  0.835378368695577,\n",
       "  0.6767362753550211,\n",
       "  0.6351432800292969,\n",
       "  0.6248999834060669],\n",
       " 'test_acc': [0.6107954545454546,\n",
       "  0.6410984848484849,\n",
       "  0.9166666666666666,\n",
       "  0.90625,\n",
       "  0.8759469696969697]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f81bc8-9a23-44d2-8ddb-393fde421b9a",
   "metadata": {},
   "source": [
    "## View our model's results in TensorBoard\n",
    "\n",
    "The SummaryWriter() class stores our model's results in a directory called `runs/` in TensorBoard format by default.\n",
    "\n",
    "TensorBoard is a visualization program create by the TensorFlow team to view and inspect information about model and the data.\n",
    "\n",
    "Now, let's visualize, visualize, and visualize.\n",
    "\n",
    "You can view TensorBoard in a number of ways:\n",
    "| **Code Environment** | **How to view TensorBoard** | **Resource** |\n",
    "| :--: | :--: | :--: |\n",
    "| VS Code (notebooks or Python scripts | Press `Shift + CMD + P -> search \"Python:launch TensorBoard\". | -- |\n",
    "|**Jupyter and Colab Notebooks**| load it with %load_ext tensorboard and then view your results with `%tensorboard -- logdir DIR_WITH_LOGS`| `torch.utils.tensorboard` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77131557-2f56-468f-bea2-9b4da6ad74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dc08c11b183cd5d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dc08c11b183cd5d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb6f44-c032-45df-bfdc-6c7bbcd18032",
   "metadata": {},
   "source": [
    "## 6. Create a helper function to build `SummaryWriter()` instances\n",
    "\n",
    "`SummaryWriter` class logs various information to a directory specified by `log_dir` parameter. `SummaryWriter(log_dir=...)`\n",
    "\n",
    "**Let's create a helper function to create a custom directory per experiment**\n",
    "\n",
    "We'd like to track things like:\n",
    "- Experiement date/timestamp\n",
    "- Experiment Name\n",
    "- Model Name\n",
    "- Extra\n",
    "  \n",
    "We can track almost anything here and be as creative as we want but these should be enough to start.\n",
    "\n",
    "Lets do:\n",
    "1. Create a helper function called `create_writer()` that produces an instance of `SummaryWriter()` with a custom `log_dir`\n",
    "2. the `log_dir` will look like `runs/YY-MM-DD/experiment_name/model_name/extra`\n",
    "3. Where `YYYY-MM-DD` is the date the experiment was run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df76ebbd-025f-41e2-a0be-4f58854e5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer(experiment_name: str,\n",
    "                  model_name: str,\n",
    "                  extra: str = None) -> torch.utils.tensorboard.SummaryWriter:\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # get timestamp of current date\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    log_dir = log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "    \n",
    "    if extra:\n",
    "        log_dir = os.path.join(log_dir, extra)\n",
    "    print(f'[INFO] Created SummaryWriter, saving to: {log_dir}')\n",
    "    \n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0b9c3-a9e7-42c7-a198-2d83855f8478",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e5beb58-c278-4cf8-8a27-31be6cedec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: runs/2024-08-19/data_10_percent/effnetb0/5_epochs\n"
     ]
    }
   ],
   "source": [
    "# Create an example writer\n",
    "example_writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb0\",\n",
    "                               extra=\"5_epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16908f9c-0d3a-4c34-bf3a-428eebb4dada",
   "metadata": {},
   "source": [
    "### 6.1 Update the `train()` function to include a `writer` paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71281a91-d980-46de-acea-2f3bcbb29fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          writer: torch.utils.tensorboard.SummaryWriter\n",
    "         ) -> Dict[str,List]:\n",
    "    \n",
    "    results = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': [],\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           device=device)\n",
    "          # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # update the results dictionary\n",
    "        results['train_loss'].append(train_loss)\n",
    "        results['train_acc'].append(train_acc)\n",
    "        results['test_loss'].append(test_loss)\n",
    "        results['test_acc'].append(test_acc)\n",
    "\n",
    "        ### Use the writer parameter to track the experiments ###\n",
    "        if writer:\n",
    "            writer.add_scalars(main_tag='Loss',\n",
    "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                                \"test_loss\": test_loss\n",
    "                                               },\n",
    "                               global_step=epoch\n",
    "                              )\n",
    "            writer.add_scalars(main_tag='Accuracy',\n",
    "                               tag_scalar_dict={\"train_acc\": train_loss,\n",
    "                                                \"test_acc\": test_loss\n",
    "                                               },\n",
    "                               global_step=epoch\n",
    "                              )\n",
    "            writer.close()\n",
    "            \n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c856a-3907-42e4-9f11-38033d26fe33",
   "metadata": {},
   "source": [
    "## 7. Setting up for multiple model/experiments\n",
    "\n",
    "What if we could `run multiple experiments` and `inspect the results all together`?\n",
    "\n",
    "Let's do that. 🔥🔥🔥🔥🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9509b6-15c3-4dce-8e9c-21461dbac30f",
   "metadata": {},
   "source": [
    "### 7.1. What kind of experiments should we run?\n",
    "\n",
    "There's no limit to the experiments we can run.\n",
    "\n",
    "We have to figure that out by doing `experiment, experiment, experiment!`\n",
    "\n",
    "Every hyperparameter stands as a starting point for a different experiment:\n",
    "- Change the number of **epochs**\n",
    "- Change the number of **layers/hidden units**\n",
    "- Change the amount of **data**\n",
    "- Change the **learning rate**\n",
    "- Try different kinds of **data augmentation**\n",
    "- Choose different **model architecture**\n",
    "\n",
    "***With practice and running many different experiments, we'll start to build an intuition of what might help our model***\n",
    "\n",
    "Generally, **`Bigger the model and bigger the data -> better the performance.`**\n",
    "\n",
    "However, if we're approaching the model for the first time, ***`We should start small` and if something works then `scale it up`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba309524-f069-4709-8442-701f4a4ea66f",
   "metadata": {},
   "source": [
    "<h3>💡💡💡\n",
    "Our first batch of experiments should take no longer than few second to few minutes.💡💡💡\n",
    "</h3>\n",
    "Because, the quicker we can experiment, the faster we can work out what works and what doesn't. 🔥🔥🔥\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507db36a-82d2-4983-b3b4-80598650a33f",
   "metadata": {},
   "source": [
    "### 7.2. Experiments we're going to run.\n",
    "\n",
    "Our goal is to improve the model without it getting too big.\n",
    "\n",
    "In essense, our ideal model achieves a high level of test set accuracy(90%+) but doesn't take too long to train/perform inference(make prediction)\n",
    "\n",
    "We've got plenty of options but how about we keep things simple?\n",
    "\n",
    "Let's try a combination of:\n",
    "1. A different amoiunt of data (10% vs 20% data)\n",
    "2. A different model(`efficientnet_b0`, `efficientnet_b2`)\n",
    "3. A different training time(5 epochs vs 10 epochs)\n",
    "\n",
    "Let's break it down\n",
    "\n",
    "| Experiment Number | Training Dataset | Model | No. of Epochs |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| 1 | 10% | EfficientNet_B0 | 5|\n",
    "| 2 | 10% | EfficientNet_B2 | 5|\n",
    "| 3 | 10% | EfficientNet_B0 | 10|\n",
    "| 4 | 10% | EfficientNet_B2 | 10|\n",
    "| 5 | 20% | EfficientNet_B0 | 5|\n",
    "| 6 | 20% | EfficientNet_B2 | 5|\n",
    "| 7 | 20% | EfficientNet_B0 | 10|\n",
    "| 8 | 20% | EfficientNet_B2 | 10|\n",
    "\n",
    "\n",
    "With each experiment, we slowly increase the amount of data, the model size and the length of training.\n",
    "\n",
    "By the end, `experiment 8` will be using `double the data`, `double the model` and `double the length of training` compared to `experiment 1`.\n",
    "🔥🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79fbb61-ad6b-4989-9de6-68ea30279882",
   "metadata": {},
   "source": [
    "### 7.3 Download different datasets\n",
    "<h3 class='h1'> Lets Download the data ⬇️ </h3>\n",
    "\n",
    "Before we start running our series of experiments, we need to make sure our datasets are ready. \n",
    "\n",
    "lets download 10% of the data and 20% of the data for Food101 - pizza, steak, and sushi\n",
    "\n",
    "***For consistency, all experiments will use the same testing dataset.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96a5daf3-39d3-454b-b09c-f59fbaffb545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data/pizza_steak_sushi directory already exists. Skipping download.\n",
      "[INFO] data/pizza_steak_sushi_20_percent doesn't exists. Creating one.\n",
      "[INFO] Downloading...\n",
      "Downloaded\n",
      "[INFO] Unzipping pizza_steak_sushi_20_percent.zip data...\n",
      "[INFO] Extracted.\n"
     ]
    }
   ],
   "source": [
    "# Download 10 percent and 20 percent training data (if necessary)\n",
    "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                                     destination=\"pizza_steak_sushi\")\n",
    "\n",
    "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                     destination=\"pizza_steak_sushi_20_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "854806ab-62b4-4261-bed7-05198fa4f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory 10%: data/pizza_steak_sushi/train\n",
      "Training directory 20%: data/pizza_steak_sushi_20_percent/train\n",
      "Testing directory: data/pizza_steak_sushi/test\n"
     ]
    }
   ],
   "source": [
    "# setup the file path for the data\n",
    "\n",
    "train_dir_10_percent = data_10_percent_path / 'train'\n",
    "train_dir_20_percent = data_20_percent_path / 'train'\n",
    "\n",
    "# setup the testing directory path\n",
    "# note: we should use the same test dataset for the both models to compare the results\n",
    "\n",
    "# Check the directories\n",
    "print(f\"Training directory 10%: {train_dir_10_percent}\")\n",
    "print(f\"Training directory 20%: {train_dir_20_percent}\")\n",
    "print(f\"Testing directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dea262-6330-4c25-9def-96e634a94bc2",
   "metadata": {},
   "source": [
    "### 7.4 Transform Datasets and create DataLoader\n",
    "\n",
    "To transform the data we can either use `manual_transform` or `automatic_transform`\n",
    "\n",
    "we'll use manual transform here. And use the same transform across all the datasets.\n",
    "\n",
    "The transform will\n",
    "1. Resize the image\n",
    "2. turn them to tensors with values between 0 and 1\n",
    "3. Normalize them in a way so that their distributions are inline with ImageNet dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0eca33a4-b16f-4719-b4f9-9dac29a79cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]\n",
    "                                )\n",
    "\n",
    "# transform\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "display(f'{normalize}', simple_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "487f7b53-cbb9-461d-9b69-cd1ed5e3b95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches of size 32 in 10 percent training data: 8\n",
      "Number of batches of size 32 in 20 percent training data: 15\n",
      "Number of batches of size 32 in testing data: 8 (all experiments will use the same test set)\n",
      "Number of classes: 3, class names: ['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "# create dataloaders\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader_10, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_10_percent,\n",
    "                                                                 test_dir=test_dir,\n",
    "                                                                 transform=simple_transform,\n",
    "                                                                 batch_size=BATCH_SIZE)\n",
    "train_dataloader_20, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
    "                                                                 test_dir=test_dir,\n",
    "                                                                 transform=simple_transform,\n",
    "                                                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(train_dataloader_10)} (all experiments will use the same test set)\")\n",
    "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3e45d-af65-432f-8378-08aa6308ca35",
   "metadata": {},
   "source": [
    "### 7.5 Lets load the model\n",
    "we load the model from `torchvision.models.<model_name>` and freeze the feature extractors and update the output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9efd02f5-e058-4bc0-b679-c2376f79d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1408, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
       "│    │    └─MBConv (1)                                       [32, 16, 112, 112]   [32, 16, 112, 112]   612                  True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    │    └─MBConv (2)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 48, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 48, 28, 28]     16,518               True\n",
       "│    │    └─MBConv (1)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     43,308               True\n",
       "│    │    └─MBConv (2)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     43,308               True\n",
       "│    └─Sequential (4)                                        [32, 48, 28, 28]     [32, 88, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 48, 28, 28]     [32, 88, 14, 14]     50,300               True\n",
       "│    │    └─MBConv (1)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     123,750              True\n",
       "│    │    └─MBConv (2)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     123,750              True\n",
       "│    │    └─MBConv (3)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     123,750              True\n",
       "│    └─Sequential (5)                                        [32, 88, 14, 14]     [32, 120, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 88, 14, 14]     [32, 120, 14, 14]    149,158              True\n",
       "│    │    └─MBConv (1)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    237,870              True\n",
       "│    │    └─MBConv (2)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    237,870              True\n",
       "│    │    └─MBConv (3)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    237,870              True\n",
       "│    └─Sequential (6)                                        [32, 120, 14, 14]    [32, 208, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 120, 14, 14]    [32, 208, 7, 7]      301,406              True\n",
       "│    │    └─MBConv (1)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    │    └─MBConv (2)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    │    └─MBConv (3)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    │    └─MBConv (4)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    └─Sequential (7)                                        [32, 208, 7, 7]      [32, 352, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 208, 7, 7]      [32, 352, 7, 7]      846,900              True\n",
       "│    │    └─MBConv (1)                                       [32, 352, 7, 7]      [32, 352, 7, 7]      1,888,920            True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 352, 7, 7]      [32, 1408, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 352, 7, 7]      [32, 1408, 7, 7]     495,616              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1408, 7, 7]     [32, 1408, 7, 7]     2,816                True\n",
       "│    │    └─SiLU (2)                                         [32, 1408, 7, 7]     [32, 1408, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1408, 7, 7]     [32, 1408, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1408]           [32, 1000]           --                   True\n",
       "│    └─Dropout (0)                                           [32, 1408]           [32, 1408]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1408]           [32, 1000]           1,409,000            True\n",
       "============================================================================================================================================\n",
       "Total params: 9,109,994\n",
       "Trainable params: 9,109,994\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 21.09\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5017.79\n",
       "Params size (MB): 36.44\n",
       "Estimated Total Size (MB): 5073.49\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchinfo import summary\n",
    "\n",
    "weights_b0 = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "weights_b2 = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "\n",
    "effnetb0 = torchvision.models.efficientnet_b0(weights=weights_b0)\n",
    "effnetb2 = torchvision.models.efficientnet_b2(weights=weights_b2)\n",
    "\n",
    "summary(model=effnetb2,\n",
    "        input_size=(32,3,224,224),\n",
    "        col_width=20,\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        row_settings=['var_names']\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08ea6a1e-4f15-4460-bef0-8ad122bc4e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of in_features to final layer of EfficientNetB2: 1408\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of in_features to final layer of EfficientNetB2: {len(effnetb2.classifier.state_dict()['1.weight'][0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da325-1976-43fa-a362-10078cf7f662",
   "metadata": {},
   "source": [
    "Now that we know the required number of `in_features` for the EffNetB2 model, let's create a couple of helper function to setup our EffNetB0 and EffNetB2 models.\n",
    "\n",
    "We want to do:\n",
    "1. Get the base models from `torchvision.models`\n",
    "2. Freeze the base layers in the model (set `requires_grad=False`)\n",
    "3. Set the random seeds\n",
    "4. Change the classifier head to suit our problem\n",
    "5. Give the model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5282609-c8f3-457b-bd38-f5c85561d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "OUT_FEATURES = len(class_names)\n",
    "\n",
    "# create an EffNetB0 feature extractor\n",
    "def create_effnetb0():\n",
    "    # 1. Get the base mdoel with pretrained weights and send to target device\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "    # 2. Freeze the base model layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # 3. set seed\\\n",
    "    set_seeds()\n",
    "\n",
    "    # 4. Change the classifier head\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    # 5. Give model a name\n",
    "    model.name = 'effnetb0'\n",
    "    print(f'[INFO] Created new {model.name} model')\n",
    "\n",
    "    return model\n",
    "\n",
    "# create an EffNetB2 feature extractor\n",
    "def create_effnetb2():\n",
    "    # 1. Get the base mdoel with pretrained weights and send to target device\n",
    "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
    "\n",
    "    # 2. Freeze the base model layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # 3. set seed\\\n",
    "    set_seeds()\n",
    "\n",
    "    # 4. Change the classifier head\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1408, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    # 5. Give model a name\n",
    "    model.name = 'effnetb2'\n",
    "    print(f'[INFO] Created new {model.name} model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd9fed-6d2c-4047-966b-c6b45c5b755b",
   "metadata": {},
   "source": [
    "Let's try them out by creating an instance of EffNetB0 and EffNetB2, and check their `summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92760121-28df-40a7-90b2-32a69e280b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnetb0 model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnetb0 = create_effnetb0()\n",
    "# Get an output summary of the layers in our EffNetB0 feature extractor model (uncomment to view full output)\n",
    "summary(model=effnetb0, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c1a67b5-2903-4226-a557-a18a51d2b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnetb2 model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1408, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    │    └─MBConv (1)                                       [32, 16, 112, 112]   [32, 16, 112, 112]   (612)                False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    │    └─MBConv (2)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 48, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 48, 28, 28]     (16,518)             False\n",
       "│    │    └─MBConv (1)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     (43,308)             False\n",
       "│    │    └─MBConv (2)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     (43,308)             False\n",
       "│    └─Sequential (4)                                        [32, 48, 28, 28]     [32, 88, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 48, 28, 28]     [32, 88, 14, 14]     (50,300)             False\n",
       "│    │    └─MBConv (1)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     (123,750)            False\n",
       "│    │    └─MBConv (2)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     (123,750)            False\n",
       "│    │    └─MBConv (3)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     (123,750)            False\n",
       "│    └─Sequential (5)                                        [32, 88, 14, 14]     [32, 120, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 88, 14, 14]     [32, 120, 14, 14]    (149,158)            False\n",
       "│    │    └─MBConv (1)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    (237,870)            False\n",
       "│    │    └─MBConv (2)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    (237,870)            False\n",
       "│    │    └─MBConv (3)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    (237,870)            False\n",
       "│    └─Sequential (6)                                        [32, 120, 14, 14]    [32, 208, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 120, 14, 14]    [32, 208, 7, 7]      (301,406)            False\n",
       "│    │    └─MBConv (1)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    │    └─MBConv (2)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    │    └─MBConv (3)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    │    └─MBConv (4)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    └─Sequential (7)                                        [32, 208, 7, 7]      [32, 352, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 208, 7, 7]      [32, 352, 7, 7]      (846,900)            False\n",
       "│    │    └─MBConv (1)                                       [32, 352, 7, 7]      [32, 352, 7, 7]      (1,888,920)          False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 352, 7, 7]      [32, 1408, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 352, 7, 7]      [32, 1408, 7, 7]     (495,616)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1408, 7, 7]     [32, 1408, 7, 7]     (2,816)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1408, 7, 7]     [32, 1408, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1408, 7, 7]     [32, 1408, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1408]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1408]           [32, 1408]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1408]           [32, 3]              4,227                True\n",
       "============================================================================================================================================\n",
       "Total params: 7,705,221\n",
       "Trainable params: 4,227\n",
       "Non-trainable params: 7,700,994\n",
       "Total mult-adds (G): 21.04\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5017.53\n",
       "Params size (MB): 30.82\n",
       "Estimated Total Size (MB): 5067.62\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnetb2 = create_effnetb2()\n",
    "# Get an output summary of the layers in our EffNetB0 feature extractor model (uncomment to view full output)\n",
    "summary(model=effnetb2, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f399fc-ad93-4119-a35d-02e7bde637ec",
   "metadata": {},
   "source": [
    "Looking at the outputs of the summaries, it seems the EffNetB2 backbone has nearly double the amount of parameters as EffNetB0.\n",
    "\n",
    "| Model | Total Parameters (before) | Total Parameters (After) | Total Trainable |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|EfficientNetB0| 5,288,548| 4,011,391 |3,843 |\n",
    "|EfficientNetB2| 9,109,994| 7,705,221 |4,227 |\n",
    "\n",
    "This gives the backbone of the EffNetB2 model more opportunities to form a representation of our pizza, steak, and sushi data.\n",
    "\n",
    "However, the trainable parameters of each model aren't very different. 🤔\n",
    "\n",
    "<span class='alert-danger'>we'll see if these extra parameter head will lead to the better results.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5717cf-4490-44f0-a974-7f1c1fa7cc58",
   "metadata": {},
   "source": [
    "### 7.6 Create Experiments and set up training code\n",
    "\n",
    "We've prepared our data and prepared our models, its **Set some experiments**\n",
    "\n",
    "We'll start by creating two lists and a dictionary.\n",
    "1. A `list` of the number of `epochs` we'd like to test (`[5,10]`)\n",
    "2. A `list` of the `models` we'd like to test (`['effnetb0','effnetb2']`)\n",
    "3. A `dictionary` of the different training `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edb1c191-e17d-4835-b2f4-c2f9331e1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create epochs list\n",
    "num_epochs = [5,10]\n",
    "\n",
    "# 2. Create models list (need to create a new model for each experiment)\n",
    "models = ['effnetb0', 'effnetb2']\n",
    "\n",
    "# 3. Create dataloaders dictionary for various dataloaders\n",
    "train_dataloaders = {\n",
    "    'data_10_percent':train_dataloader_10,\n",
    "    'data_20_percent':train_dataloader_20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b08354-dc4e-4ccb-9307-72814535b8b2",
   "metadata": {},
   "source": [
    "Lists and dictionary created.\n",
    "\n",
    "Now we can write the code to `iterate` through each of the different options and try out each of the different combinations.\n",
    "\n",
    "We'll also `save the model` at the end of each experiment so `later` on we can `load back` in the best model and `use it for making predictions`.\n",
    "\n",
    "Specifically, let's go through the following steps:\n",
    "1. Set the random seeds (so that our experiment results are reproducible)\n",
    "2. Keep track of different experiment numbers.\n",
    "3. Loop through the `train_dataloaders` dictionary items for each of the different training DataLoaders.\n",
    "4. Loop through the list of epoch numbers\n",
    "5. Loop through the list of different model names.\n",
    "6. Create information print outs for the current running experiments (so we know whats happening)\n",
    "7. Check which model is the target model and create a new EffNetB0 or EffnetB2 (we create new instance of the model in each experiment so all models start from the same standpoint)\n",
    "8. Create a new `loss function - torch.nn.CrossEntropyLoss()` and an `optimizer - torch.optim.Adam(params=model.parameters(), lr=0.001)` for each new experiment\n",
    "9. Train the model with `the modified train() function` passing the appropriate details to the writer parameter\n",
    "10. Save the trained model with an appropriate file name to file with `save_model()` from `utils.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b83773-21bf-412d-af75-a6a2fc37aeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Experiment number: 1\n",
      "[INFO] Model: effnetb0\n",
      "[INFO] DataLoader: data_10_percent\n",
      "[INFO] Number of epochs: 5\n",
      "[INFO] Created new effnetb0 model\n",
      "[INFO] Created SummaryWriter, saving to: runs/2024-08-19/data_10_percent/effnetb0/5_epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f842f3df4043459e2649acd8f8fce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from going_modular.going_modular.utils import save_model\n",
    "\n",
    "# 1. set random seeds\n",
    "set_seeds(seed=42)\n",
    "\n",
    "# 2. Keep track of experiment numbers\n",
    "experiment_number = 0\n",
    "\n",
    "# 3. Loop through each DataLoader\n",
    "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
    "\n",
    "    # 4. Loop through each number of epochs\n",
    "    for epochs in num_epochs:\n",
    "\n",
    "        # 5. Loop through each model name and create a new model based on the name\n",
    "        for model_name in models:\n",
    "\n",
    "            # 6. Create information print outs\n",
    "            experiment_number += 1\n",
    "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
    "            print(f\"[INFO] Model: {model_name}\")\n",
    "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
    "            print(f\"[INFO] Number of epochs: {epochs}\")  \n",
    "\n",
    "            # 7. Select the model\n",
    "            if model_name == 'effnetb0':\n",
    "                model = create_effnetb0() # creates a new model each time\n",
    "            else:\n",
    "                model = create_effnetb2()\n",
    "\n",
    "            # 8. Create a new loss and optimizer for every model\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                        lr=0.001\n",
    "                                        )\n",
    "            # 9. Train target model with target dataloaders and track experiments\n",
    "            train(model=model,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  loss_fn=loss_fn,\n",
    "                  optimizer=optimizer,\n",
    "                  epochs=epochs,\n",
    "                  device=device,\n",
    "                  writer=create_writer(experiment_name=dataloader_name,\n",
    "                                       model_name=model_name,\n",
    "                                       extra=f'{epochs}_epochs')\n",
    "                 )\n",
    "            # 10. Save the model to file so we can get back the best model\n",
    "            save_filepath = f'07_{model_name}_{dataloader_name}_{epochs} epoch.pth'\n",
    "            save_model(model=model,\n",
    "                       target_dir='models',\n",
    "                       model_name=save_filepath)\n",
    "            print(\"-\"*50+'\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa519cf-1134-4147-97d0-e5cb7d867e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
